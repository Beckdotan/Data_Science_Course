{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8704145",
   "metadata": {},
   "source": [
    "# Hw3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7792f5",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34530a33",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b40f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "from sklearn import metrics \n",
    "import os\n",
    "##import pydotplus \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d20232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=\"car_evaluation.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "df_class_names=['Acceptable','NOT Acceptable']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c543847",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22ebfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raws: 1728\n",
      "Columns: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_price</th>\n",
       "      <th>num_doors</th>\n",
       "      <th>num_persons</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_price  maintenance_price  num_doors  num_persons  luggage_boot  \\\n",
       "0             3                  3          1            1             3   \n",
       "1             3                  3          1            3             1   \n",
       "2             2                  3          4            2             3   \n",
       "3             4                  1          1            3             2   \n",
       "4             4                  2          3            3             1   \n",
       "\n",
       "   safety  acceptable  train  \n",
       "0       3           0      1  \n",
       "1       1           0      1  \n",
       "2       3           1      1  \n",
       "3       1           0      1  \n",
       "4       3           1      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def getSize(df):\n",
    "    print('Raws:',df.shape[0])\n",
    "    print('Columns:',df.shape[1])\n",
    "    \n",
    "    \n",
    "getSize(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00d0f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 1178\n",
      "Test: 550\n"
     ]
    }
   ],
   "source": [
    "## 5. Based on how many cars the algorithm will be trained and tested? \n",
    "##    (Provide a numerical answer for both train and test)\n",
    "\n",
    "def get_amount_of_raws_with_value(df,column, value):\n",
    "    if value == 1:\n",
    "        print(\"Training:\" , df[df[column] == value].shape[0])\n",
    "    else:\n",
    "         print(\"Test:\" , df[df[column] == value].shape[0])\n",
    "    \n",
    "\n",
    "get_amount_of_raws_with_value(df, \"train\", 1)\n",
    "get_amount_of_raws_with_value(df, \"train\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ca3a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features =  7\n"
     ]
    }
   ],
   "source": [
    "# 6. How many features each car is represented by? (Provide a numerical answer)\n",
    "\n",
    "def getSize(df):\n",
    "    print('Amount of features = ',df.shape[1]-1)\n",
    "    \n",
    "    \n",
    "getSize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ae116",
   "metadata": {},
   "source": [
    "7. Which features are categorized as predictors? (Provide a verbal answer)\n",
    "\n",
    "the predictors are :  buying_price,  maintenance_price , num_doors, num_persons, luggage_boot , safety\n",
    "\n",
    "8. Which features are categorized as the label (target(? (Provide a verbal answer)\n",
    "the target / label is acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37340818",
   "metadata": {},
   "source": [
    "## PART 2: BUILDING A DECISION TREE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46cbe67",
   "metadata": {},
   "source": [
    "### TASK 4: BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7df985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. In next page you will see visual representation of the tree.\n",
    "\n",
    "def get_predictors_names(dataframe):\n",
    "    names = list(dataframe.columns)\n",
    "    predictors_names=names[:-2]\n",
    "    return predictors_names\n",
    "df_predictors_names = get_predictors_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "545aec1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buying_price',\n",
       " 'maintenance_price',\n",
       " 'num_doors',\n",
       " 'num_persons',\n",
       " 'luggage_boot',\n",
       " 'safety']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictors_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564255cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nd(dataframe):\n",
    "    nd=dataframe.values\n",
    "    return nd\n",
    "nd= get_nd(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99471f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 1, ..., 3, 0, 1],\n",
       "       [3, 3, 1, ..., 1, 0, 1],\n",
       "       [2, 3, 4, ..., 3, 1, 1],\n",
       "       ...,\n",
       "       [2, 2, 1, ..., 2, 0, 1],\n",
       "       [3, 3, 4, ..., 2, 1, 1],\n",
       "       [1, 3, 2, ..., 3, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7138dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_no(dataframe):\n",
    "    row_no,col_no =dataframe.shape\n",
    "    return col_no\n",
    "col_no=get_col_no(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce033791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split array into train and test\n",
    "def get_nd_train_test(ndarray, train_index):\n",
    "    nd_train =ndarray[ndarray[:, col_no-1] == 1]\n",
    "    nd_test = ndarray[ndarray[:, col_no-1] == 0]\n",
    "    return nd_train,nd_test\n",
    "nd_train,nd_test= get_nd_train_test(nd,col_no-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b20790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 1, ..., 3, 0, 1],\n",
       "       [3, 3, 1, ..., 1, 0, 1],\n",
       "       [2, 3, 4, ..., 3, 1, 1],\n",
       "       ...,\n",
       "       [2, 2, 1, ..., 2, 0, 1],\n",
       "       [3, 3, 4, ..., 2, 1, 1],\n",
       "       [1, 3, 2, ..., 3, 1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc3eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors label separations\n",
    "# X include the predictors columns\n",
    "# Y is the label column\n",
    "def get_XY(ndarray):\n",
    "    X=ndarray[:,:-2]\n",
    "    Y= ndarray[:,-2]\n",
    "    return X,Y\n",
    "X_train,Y_train = get_XY(nd_train)\n",
    "X_test,Y_test = get_XY(nd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea483266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with training data\n",
    "def get_clf(X,Y):\n",
    "    clf= DecisionTreeClassifier( criterion=\"gini\",  min_impurity_decrease=0.01)\n",
    "    clf.fit(X, Y)\n",
    "    return(clf)\n",
    "clf=get_clf(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "514ef949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for testing data\n",
    "def get_pred(classifier, X):\n",
    "    y_pred = classifier.predict(X)\n",
    "    return(y_pred)\n",
    "y_pred = get_pred(clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be8aa778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for att =  1\n",
      "Group Size =  407\n",
      "Inner Sigma Calc  1.0\n",
      "mid - result  0.0\n",
      "------------------\n",
      "for att =  2\n",
      "Group Size =  388\n",
      "Inner Sigma Calc  0.5257200552662344\n",
      "mid - result  0.15621444699210615\n",
      "------------------\n",
      "for att =  3\n",
      "Group Size =  383\n",
      "Inner Sigma Calc  0.5005760486471379\n",
      "mid - result  0.1623763780714314\n",
      "------------------\n",
      "over all answer =  0.31859082506353753\n",
      "it represents that  0.31859082506353753  is the probability of the predictor (saftey <= 1.5)  being classified incorrectly when selected randomly \n"
     ]
    }
   ],
   "source": [
    "#As can be seen from the decision tree, the attribute that was selected for the root of the tree is ‘Safety’.\n",
    "#The Gini index value of this attribute is 0.416.\n",
    "#Provide a detailed calculation of this value (Hint: You can use Excel to perform the calculation).\n",
    "\n",
    "\n",
    "##\n",
    "\n",
    "##claculation:\n",
    "def calc_gini_by_cul(att,df, col):\n",
    "        print(\"for att = \", att)\n",
    "        total_amount = df.shape[0]\n",
    "        att_amount = df[df[:,col] == att]\n",
    "        print(\"Group Size = \", att_amount.shape[0])\n",
    "        acceptable = att_amount[att_amount[:,6] == 1].shape[0]\n",
    "        unacceptable = att_amount[att_amount[:,6] == 0].shape[0]\n",
    "\n",
    "        inner_sigma_calc = pow(acceptable/att_amount.shape[0],2) + pow(unacceptable/att_amount.shape[0],2)\n",
    "        print(\"Inner Sigma Calc \" , inner_sigma_calc)\n",
    "        result = (1-inner_sigma_calc)*(att_amount.shape[0]/total_amount)\n",
    "        print(\"mid - result \" , result)\n",
    "        print(\"------------------\")\n",
    "        return result\n",
    "            \n",
    "            \n",
    "sum = 0           \n",
    "for x in [1,2,3]:\n",
    "    sum += calc_gini_by_cul(x,nd_train,5)\n",
    "         \n",
    "print(\"over all answer = \", sum)\n",
    "print(\"it represents that \", sum, \" is the probability of the predictor (saftey <= 1.5)  being classified incorrectly when selected randomly \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86fa61d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Sigma Calc  0.5837092594567639\n",
      "result  0.4162907405432361\n",
      "That is the overall chance to choose acceptable car from random chose on the hole training data\n"
     ]
    }
   ],
   "source": [
    "total_amount = nd_train\n",
    "acceptable = total_amount[total_amount[:,6] == 1].shape[0]\n",
    "unacceptable = total_amount[total_amount[:,6] == 0].shape[0]\n",
    "inner_sigma_calc = pow(acceptable/total_amount.shape[0],2) + pow(unacceptable/total_amount.shape[0],2)\n",
    "print(\"Inner Sigma Calc \" , inner_sigma_calc)\n",
    "result = (1-inner_sigma_calc)*(total_amount.shape[0]/total_amount.shape[0])\n",
    "print(\"result \" , result)\n",
    "\n",
    "print(\"That is the overall chance to choose acceptable car from random chose on the hole training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f1c111",
   "metadata": {},
   "source": [
    "11. Below are three used cars offered for sale. Based on the decision tree, determine for each of them whether it will be acceptable or not (Provide a verbal answer):\n",
    "\n",
    "\n",
    "1. Car with a low buying price, very high maintenance price, 3 doors, 2 persons can be carried, medium luggage boot and low in safety.\n",
    "\n",
    "-- ans: \n",
    "We will start from the root. becouse its low on safty then by def its 1 than becouse 1<=1.5 than we will go to true and we finished. \n",
    "By our model we think that its unacceptable. \n",
    "\n",
    "\n",
    "2. Car with a high or very high buying price, medium maintenance price, 4 doors, 4 or more persons can be carried, big luggage boot and medium or high in safety.\n",
    "\n",
    "-- ans: \n",
    "sicnce it has medium or high safty than the score will be 2+ > 1.5 than in the root we will go right to false.\n",
    "Because num of persons (4) >= 1.5 we will go to false again. \n",
    "Than becouse buying price is high (2) <= 2.5 than we will go left (true). \n",
    "Than becouse its very high maintnens (1) <=2.5 we will go left (true) and \n",
    "Finish with unacceptable. \n",
    "\n",
    "3. Car with a medium buying, low maintenance price, 2 doors, 2 persons can be carried, small luggage boot and medium or high in safety.\n",
    "\n",
    "-- ans: \n",
    "sicnce it has medium or high safty than the score will be 2+ > 1.5 than in the root we will go right to false.\n",
    "Because num of persons (2) >= 1.5 we will go to false again. \n",
    "Than becouse buying price is medium (3) > 2.5 than we will go right (false).\n",
    "Since it have  small luggage boot (1) <= 1.5 than we will go for true again. \n",
    "Than finish in Acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319bc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52686a97",
   "metadata": {},
   "source": [
    "###  TASK 5: EVALUATE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a677638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is : 0.92\n"
     ]
    }
   ],
   "source": [
    "# Use the Accuracy measure to evaluate the mode you have created in Task 4.\n",
    "def get_accuracy(test,pred): \n",
    "    accuracy = metrics.accuracy_score(test, pred)\n",
    "    return accuracy\n",
    "clf_accuracy=get_accuracy(Y_test,y_pred) \n",
    "print(f'The accuracy is : {clf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83806be4",
   "metadata": {},
   "source": [
    "13. (Use your own words) Describe, in the context of the model you have built, the\n",
    "meaning of the numerical result you have received for the Accuracy measure (Provide a verbal answer using terms such as classification matrix, True Positive, etc.)\n",
    "\n",
    "the accuracy of our model is 0.92 - which mean than in 92% of the given testings we were right so we were on the first type of cells in the  classification matrix\n",
    "\n",
    "The classification matrix is sapareted to 4 cells. \n",
    "\n",
    "First type: 2 cells represent correct answers : we predicted unacceptable and its realy unacceptable, or we predicted acceptable and its really acceptable.\n",
    "\n",
    "second type: The other 2 cells are in-corrent answers:  we predicted unacceptable but its realy acceptable, or we predicted acceptable but its really unacceptable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4977df0",
   "metadata": {},
   "source": [
    "14. (Use your own words) Describe one prominent disadvantage of the Accuracy measure you have calculated.\n",
    "\n",
    "This accuracy measure is assuming that every result have the same \"power\" on the output - which is not always currect. \n",
    "\n",
    "for example: if we want to make the movie sugestions algorithem for NETFLIX than we want to offer people who \"agreed\" = watched simillar films more then people who didnt watch the same movies. thats becouse that choosing the same movie is a lot more powerful then not watching the same  movies in netflix becouse there are so many, and it can just happen that one of the costumers missed it or never even saw the option to see it. \n",
    "\n",
    "there fore we will have to give a lot more whight to the movies they choose to see rother than the one they didnt - which this altorithem doesnt provide.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761638b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd63b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ebe3627",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pydotplus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hk/trvt3xwd40g0hh8f4t55l3540000gn/T/ipykernel_40330/3434330406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_predictors_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/hk/trvt3xwd40g0hh8f4t55l3540000gn/T/ipykernel_40330/3434330406.py\u001b[0m in \u001b[0;36mget_graph\u001b[0;34m(clf, df_predictors_names)\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_predictors_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 class_names=df_class_names)\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_predictors_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pydotplus' is not defined"
     ]
    }
   ],
   "source": [
    "# alculate Accuracy, frequency of cases when the classifier is correct\n",
    "def get_graph(clf,df_predictors_names):\n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                                feature_names=df_predictors_names,  \n",
    "                                class_names=df_class_names)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "    return graph\n",
    "graph =get_graph(clf,df_predictors_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d0de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cbc41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33171607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
